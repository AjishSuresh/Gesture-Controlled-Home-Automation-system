âœ‹ Hand Gesture Recognition for Home Automation ğŸ 

ğŸ“ Project Description

This project implements a real-time hand gesture recognition system designed for home automation, particularly beneficial for individuals with speech impairments. The system uses computer vision and machine learning to detect hand gestures through a camera, classify them, and control home appliances via IoT integration.

âœ¨ Key Features:

ğŸ–ï¸ Real-time hand detection using MediaPipe

ğŸ¤– Custom gesture classification with TensorFlow Lite

â˜ï¸ Adafruit IO integration for smart home control

ğŸ¯ 94% accuracy in gesture recognition

â™¿ Designed for accessibility and ease of use

ğŸ› ï¸ Installation
ğŸ“‹ Prerequisites
Python 3.7+

pip (Python package manager)

ğŸ“¦ Dependencies

Install the required packages using:

bash
pip install --upgrade pip
pip install mediapipe numpy tensorflow opencv-python Adafruit-IO
ğŸš€ Usage
ğŸ”§ Setup Adafruit IO:

Create an account at Adafruit IO

Create feeds for your devices (e.g., 'mode', 'r1s1', 'r2s1', etc.)

Update credentials in app.py:

python
ADAFRUIT_IO_USERNAME = 'your_username'
ADAFRUIT_IO_KEY = 'your_key'
ğŸƒ Run the application:

bash
python app.py
ğŸ‘‹ Gesture Controls:

The system starts in 'standby' mode

Show gesture combinations to control devices:

âœŒï¸ + ğŸ‘: Switch to 'detection' mode

âœ‹ + â˜ï¸: Control Relay 1 Switch 1

ğŸ–ï¸ + â˜ï¸: Control Relay 1 Switch 2

âœ‹ + âœŒï¸: Control Relay 2 Switch 1

ğŸ–ï¸ + âœŒï¸: Control Relay 2 Switch 2

ğŸšª Exit:

Press ESC to quit the application

ğŸ“‚ File Structure

hand-gesture-home-automation/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ keypoint_classifier/
â”‚   â”‚   â”œâ”€â”€ keypoint_classifier.tflite  # ğŸ§  ML model
â”‚   â”‚   â”œâ”€â”€ keypoint_classifier_label.csv  # ğŸ·ï¸ Gesture labels
â”‚   â”‚   â””â”€â”€ keypoint.csv  # ğŸ“Š Training data
â”œâ”€â”€ app.py  # ğŸš€ Main application
â”œâ”€â”€ record.py  # ğŸ“¹ Gesture recording
â”œâ”€â”€ keypoint_classifier.py  # ğŸ¤– Model wrapper
â””â”€â”€ README.md  # ğŸ“– This file
ğŸ“ Training Custom Gestures

To add new gestures:

Run the recording script:

bash
python record.py
Press number keys (0-9) to label gestures

Collect 50-100 samples per gesture âœ‹

Retrain model with new data

ğŸ“Š Performance
âœ… Accuracy: 94%

âš¡ Processing: 3s delay for stable recognition

ğŸ‘¥ Supports multiple hand detection

ğŸ”Œ Hardware Setup
Recommended components:

ğŸ“ Raspberry Pi 400

ğŸ“¶ ESP8266 WiFi modules

ğŸ”Œ Relay modules

ğŸ“· USB webcam

ğŸ¤ Contributing
Contributions welcome! Please:

ğŸ´ Fork the repository

ğŸŒ± Create your feature branch

ğŸ’¾ Commit your changes

ğŸ”€ Push to the branch

ğŸ¯ Open a pull request


ğŸ™ Acknowledgments

MediaPipe for hand tracking

TensorFlow Lite for efficient inference

Adafruit for IoT platform

â“ Support

For issues, please open an issue on GitHub. We're happy to help! ğŸ’¬

